{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import feather\n",
    "import pyspark\n",
    "import logging\n",
    "import json\n",
    "from tqdm import tqdm\n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.ml.linalg import Vectors\n",
    "from pyspark.ml.feature import VectorAssembler,StringIndexer\n",
    "from pyspark.sql.functions import countDistinct,count,isnan,isnull\n",
    "from pyspark.sql import functions as F\n",
    "\n",
    "from pyspark.ml.recommendation import ALS,ALSModel\n",
    "from pyspark.ml.evaluation import RegressionEvaluator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "def spark_shape(self):\n",
    "    return (self.count(),len(self.columns))\n",
    "pyspark.sql.dataframe.DataFrame.shape = spark_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "#defining the paths for the MovieLens dataset\n",
    "PATH = r\"C:\\Users\\Kaumil-Trivedi\\Documents\\kaumil\\datasets\\ml-1m\\ml-1m\"\n",
    "MODEL_PATH =r\"C:\\Users\\Kaumil-Trivedi\\Documents\\kaumil\\spark_tutorials\\spark_framework\\saved_models\"\n",
    "HYPERPARAMETERS_PATH = r\"C:\\Users\\Kaumil-Trivedi\\Documents\\kaumil\\spark_tutorials\\spark_framework\\hyperparameters\"\n",
    "FINAL_RESULTS_PATH = r\"C:\\Users\\Kaumil-Trivedi\\Documents\\kaumil\\spark_tutorials\\spark_framework\"\n",
    "\n",
    "#initializing seed\n",
    "random_seed = 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Defining Spark Session\n",
    "spark = (SparkSession\n",
    "         .builder\n",
    "         .master(\"local[*]\")\n",
    "         .appName(\"Recommender\")\n",
    "         .config(\"spark.sql.execution.arrow.enabled\",\"true\")\n",
    "         .getOrCreate())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reading Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ratings = feather.read_dataframe(os.path.join(PATH,\"ratings.feather\"))\n",
    "df_movies = feather.read_dataframe(os.path.join(PATH,\"movies.feather\"))\n",
    "df_users = feather.read_dataframe(os.path.join(PATH,\"users.feather\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ratings = spark.createDataFrame(df_ratings)\n",
    "df_movies = spark.createDataFrame(df_movies)\n",
    "df_users = spark.createDataFrame(df_users)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data,testing_data = df_ratings.randomSplit([0.8,0.2],seed=random_seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ratings  & Movies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final_ratings = df_ratings.select(['UserID', 'MovieID', 'Rating'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final_movies = df_movies.select(['MovieID','Title'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Preprocessing Movie Titles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# movie_title_indexer = StringIndexer(inputCol=\"Title\",outputCol=\"TitleIndex\")\n",
    "# movie_indexer_model = movie_title_indexer.fit(df_final_movies)\n",
    "# df_final_movies = movie_indexer_model.transform(df_final_movies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ratings_assembler = VectorAssembler(inputCols=df_final_ratings.columns,outputCol=\"rating_features\")\n",
    "# movies_assembler = VectorAssembler(inputCols=['MovieID','TitleIndex'],outputCol=\"movies_features\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_final_ratings = ratings_assembler.transform(df_final_ratings).select(\"rating_features\")\n",
    "# df_final_movies = movies_assembler.transform(df_final_movies).select(\"movies_features\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings_train, ratings_test = df_final_ratings.randomSplit([0.8,0.2],seed=random_seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "iterations = 10\n",
    "regularization_parameter = 0.1\n",
    "ranks = [4,8,12]\n",
    "errors = [0,0,0]\n",
    "err_index = 0\n",
    "coldStartStrategy = \"drop\"\n",
    "\n",
    "min_error = float('inf')\n",
    "best_rank = -1\n",
    "best_iteration = -1\n",
    "\n",
    "#Regression Evaluator\n",
    "reg_eval = RegressionEvaluator(predictionCol=\"prediction\",\\\n",
    "                               labelCol=\"Rating\",\\\n",
    "                               metricName=\"rmse\")\n",
    "\n",
    "results = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_json(**kwargs):\n",
    "    \"\"\"Accepts a list of keyword parameters and returns a json consisting the name and the value of the parameter\"\"\"\n",
    "    \n",
    "    try:\n",
    "        return json.dumps(kwargs)\n",
    "    \n",
    "    except Exception as e:\n",
    "        logging.exception(\"Exception in creating the json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluators(predictions,**kwargs):\n",
    "    \"\"\"Accepts a PySpark SQL Dataframe, runs all the evaluations on it with the evaluators provided and outputs the results\"\"\"\n",
    "    \n",
    "    if (str(type(predictions)) != \"<class 'pyspark.sql.dataframe.DataFrame'>\") or (\"prediction\" not in predictions.columns):\n",
    "        raise Exception(\"Inconsistent dataframe passed for predictions\")\n",
    "    try:\n",
    "        \n",
    "        results = {}\n",
    "        for arg in kwargs:\n",
    "            evaluator = kwargs[arg]\n",
    "            results[arg] = {}\n",
    "            \n",
    "            results[arg][\"metric_value\"] = evaluator.evaluate(predictions)\n",
    "            results[arg][\"metric_name\"] = evaluator.getMetricName()\n",
    "        \n",
    "        return results\n",
    "    except Exception as ex:\n",
    "        logging.exception(\"Exception in calculating the evaluations\")\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_and_save_json(data,path,file_name=None,file_path_name_inclusive=True):\n",
    "    \"\"\"Accepts data, converts it to JSON and saves it to the path provided\"\"\"\n",
    "    \n",
    "    try:\n",
    "        json_file = json.dumps(data)\n",
    "        file_path = None\n",
    "        \n",
    "        #saving it to the path\n",
    "        if file_path_name_inclusive == True:\n",
    "            file_path = path\n",
    "        else:\n",
    "            if file_name == None:\n",
    "                raise Exception(\"Please provide a file name in the file path or as a parameter\")\n",
    "            file_path = os.path.join(path,file_name)\n",
    "        \n",
    "        with open(file_path,\"w\",encoding=\"utf-8\") as JSONFile:\n",
    "            json.dump(json_file,JSONFile)\n",
    "    \n",
    "    except Exception as e:\n",
    "        logging.Exception(\"Exception in creating and saving JSON file\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "  0%|                                                                                 | 0/3 [00:00<?, ?it/s]\n",
      "\n",
      " 33%|████████████████████████▎                                                | 1/3 [00:57<01:54, 57.15s/it]\n",
      "\n",
      " 67%|████████████████████████████████████████████████▋                        | 2/3 [01:57<00:58, 58.11s/it]\n",
      "\n",
      "100%|█████████████████████████████████████████████████████████████████████████| 3/3 [03:05<00:00, 61.20s/it]"
     ]
    }
   ],
   "source": [
    "for rank in tqdm(ranks):\n",
    "    als = ALS(rank=rank,\\\n",
    "              seed=random_seed,\\\n",
    "              regParam=regularization_parameter,\\\n",
    "              maxIter=iterations,\\\n",
    "              coldStartStrategy= coldStartStrategy,\\\n",
    "              userCol='UserID',\\\n",
    "              itemCol='MovieID',\\\n",
    "              ratingCol=\"Rating\")\n",
    "    model = als.fit(ratings_train)\n",
    "    \n",
    "    rank_string = \"rank\"+str(rank)\n",
    "    \n",
    "    #saving the model to a specified path,eliminating the need to retrain the models later\n",
    "    model.save(os.path.join(MODEL_PATH,rank_string))\n",
    "    \n",
    "    #saving the hyperparameters and the error values for this model\n",
    "    hyperparameter_json = create_json(rank=rank,\\\n",
    "                                      seed=random_seed,\\\n",
    "                                      regularization_parameter=regularization_parameter,\\\n",
    "                                      coldStartStrategy=coldStartStrategy)\n",
    "    \n",
    "    evaluators_json = evaluators(test_prediction,regression=reg_eval)\n",
    "    \n",
    "    \n",
    "    test_prediction = model.transform(ratings_test)\n",
    "    results[rank_string] = {\n",
    "        \"Hyperparameters\": hyperparameter_json,\n",
    "        \"Errors\": evaluators_json\n",
    "    }\n",
    "    \n",
    "    create_and_save_json(data=hyperparameter_json,path=os.path.join(MODEL_PATH,rank_string,\"hyperparameters.json\"),file_path_name_inclusive=True)\n",
    "    create_and_save_json(data=evaluators_json,path=os.path.join(MODEL_PATH,rank_string,\"evaluators.json\"),file_path_name_inclusive=True)\n",
    "create_and_save_json(data = results,path=FINAL_RESULTS_PATH,file_name=\"results.json\",file_path_name_inclusive=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Getting Average Rating for each movie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "def return_avg(dataframe,groupBy_column:str,target_column:str,alias_name=None):\n",
    "    \n",
    "    \"\"\"Returns a new PySpark Dataframe computing the avg value of the column\"\"\"\n",
    "    \n",
    "    if alias_name == None:\n",
    "        alias_name = \"avg_\"+str(target_column)\n",
    "    \n",
    "    return dataframe.groupBy([groupBy_column]).agg(F.mean(target_column).alias(alias_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_avg_movie_ratings = return_avg(df_final_ratings,\"MovieID\",\"Rating\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final_movies = df_final_movies \\\n",
    ".join(df_avg_movie_ratings,df_final_movies['MovieID']==df_avg_movie_ratings['MovieID'],how='full') \\\n",
    ".select(F.coalesce(df_final_movies['MovieID'],\\\n",
    "                   df_avg_movie_ratings['MovieID']).alias('MovieID'),\\\n",
    "        df_final_movies['Title'],\\\n",
    "        df_avg_movie_ratings['avg_Rating'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Sample User"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-------+------+\n",
      "|UserID|MovieID|Rating|\n",
      "+------+-------+------+\n",
      "|     0|    260|     9|\n",
      "|     0|      1|     8|\n",
      "|     0|     16|     7|\n",
      "|     0|     25|     8|\n",
      "|     0|     32|     9|\n",
      "|     0|    335|     4|\n",
      "|     0|    379|     3|\n",
      "|     0|    296|     7|\n",
      "|     0|    858|    10|\n",
      "|     0|     50|     8|\n",
      "+------+-------+------+\n",
      "\n",
      "New user ratings: None\n"
     ]
    }
   ],
   "source": [
    "new_user_ID = 0\n",
    "\n",
    "# The format of each line is (userID, movieID, rating)\n",
    "new_user_ratings = [\n",
    "     (0,260,9),\n",
    "     (0,1,8),\n",
    "     (0,16,7),\n",
    "     (0,25,8),\n",
    "     (0,32,9),\n",
    "     (0,335,4),\n",
    "     (0,379,3),\n",
    "     (0,296,7),\n",
    "     (0,858,10),\n",
    "     (0,50,8)\n",
    "    ]\n",
    "df_new_user_ratings = spark.createDataFrame(new_user_ratings,['UserID','MovieID','Rating'])\n",
    "print('New user ratings: %s' % df_new_user_ratings.show(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Adding the ratings given by the user to the ratings dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final_ratings = df_final_ratings.union(df_new_user_ratings)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Training the best model on the new dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "als = ALS(rank=best_rank,\\\n",
    "          seed=random_seed,\\\n",
    "          regParam=regularization_parameter,\\\n",
    "          maxIter=iterations,\\\n",
    "          userCol='UserID',\\\n",
    "          itemCol='MovieID',\\\n",
    "          ratingCol=\"Rating\",\\\n",
    "          coldStartStrategy=\"drop\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = als.fit(df_final_ratings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ALS_d9a6330ce9ae"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fetching the Movie IDs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "movie_ids = df_final_movies.select(['MovieID'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-------+------+\n",
      "|UserID|MovieID|Rating|\n",
      "+------+-------+------+\n",
      "|     0|    260|     9|\n",
      "|     0|      1|     8|\n",
      "|     0|     16|     7|\n",
      "|     0|     25|     8|\n",
      "|     0|     32|     9|\n",
      "|     0|    335|     4|\n",
      "|     0|    379|     3|\n",
      "|     0|    296|     7|\n",
      "|     0|    858|    10|\n",
      "|     0|     50|     8|\n",
      "+------+-------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_new_user_ratings.show(n=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3880, 1)"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movie_ids.filter(movie_ids['MovieID'].isin([1,2,3]) == False).shape()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Column<b'MovieID'>"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_new_user_ratings[\"MovieID\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[UserID: bigint, MovieID: bigint, Rating: bigint]"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_final_ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
